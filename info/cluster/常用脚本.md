
## 简介
pycluster2x扩展包2.3.6后增加script脚本子模块```pycluster2x.script```

支持脚本查看方法
```
python3 -m pycluster2x.script -l
```
输出如
```
script list:
-------------------------
download_data                   下载数据到数据缓存
old_process                     使用老流程(大分区小分区逐级归并流程)进行聚档
upload_result                   上传聚类结果到自动化测试平台数据库
multi_core                      老流程，使用分模态oc接口，可以配置支持多计算核心
```

说明文字来源于脚本的doc信息

所有脚本可通过-h查看可选设置，例如```python3 -m pycluster2x.script.upload_result -h```




## 一些脚本说明：

### 1. old_process （流程测试）
这个脚本用于单卡主流程测试，该流程为聚档常用测试流程。使用old_process时，运行命令如：

```gdb --args python3 -m pycluster2x.script.old_process --data_host 10.12.76.155 --data_port 33508 --result_host 10.12.76.155 --result_port 23508  --task 3035 --result_path ./result/ --result_name result --device_id 0 --data_cache ./data_cache/```

其中--result_path是希望保存结果的路径，--result_host、--result_port和--task分别是结果数据服务的ip、端口和任务号，任务结束后如果设置了这几个字段，结果会通过结果数据服务上传到表名为--result_name的表中。--data_host和--data_port分别是数据服务的ip、端口，--device_id是使用的设备id，--data_cache是现有或希望保存的缓存数据路径。

未填写结果result_host、result_port、result_task时不上传结果到自动化测试平台，填写时运行完成后会自动上传结果

结果和中间结果会保存到当前路径的./result/目录，最终结果为./result/all/

可以通过```python3 -m pycluster2x.script.old_process -h``` 查看参数说明

------------------

### 2. multi_core（流程测试）
这个脚本用于多卡主流程测试，该流程为聚档常用测试流程。使用multi_core时，运行命令如：

```python3 -m pycluster2x.script.multi_core --data_host 10.12.76.155 --data_port 33508 --result_host 10.12.76.155 --result_port 23508  --task 3035 --result_path ./result/ --result_name result --device_id 0 --oc_size 2400000 --data_cache ./data_cache/```

同 1.old_process ，其中--result_path是希望保存结果的路径，--result_host、--result_port和task分别是结果数据服务的ip、端口和任务号，任务结束后如果设置了这几个字段，结果会通过结果数据服务上传到表名为--result_name的表中。--data_host和--data_port分别是数据服务的ip、端口，--data_cache是现有或希望保存的缓存数据路径。不同在于使用分模态oc进行合档，合档接口支持拆分抵挡进入多卡进行计算，使用--device_id 0 1 设置多张卡的卡号，使用--oc_size 2400000设置每次oc支持的最大底档人数，--oc_size默认为2400000

未填写结果result_host、result_port、result_task时不上传结果到自动化测试平台，填写时运行完成后会自动上传结果

可以通过```python3 -m pycluster2x.script.multi_core -h``` 查看参数说明

----------------

（**注：** old_process和multi_core脚本在pycluster2x 2.4以前，必须依赖[pydata_service数据服务扩展包](https://yfgitlab.dahuatech.com/clustering/alg_personcluster/-/wikis/pydata_service%E6%89%A9%E5%B1%95%E5%8C%85/%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1pydata_service%E4%BD%BF%E7%94%A8)，必须设置数据来源的host和port，2.4版本后，如果有现成数据缓存，可以不依赖数据服务，运行时可以不传数据服务的ip和端口）

----------------

### 3. upload_result
2.3.5版本之后，可以使用upload_result上传结果到服务器，使用如
```python3 -m pycluster2x.script.upload_result ./result/all/ --result_host 10.12.76.155 --result_port 39185 --task 3035```
其中```./result/all/```是结果路径，后面result_host、result_port和task分别是结果数据服务的ip、端口和任务号

---------------------------------

### 4. download_data
2.3.5版本之后，可以使用download_data从服务器下载数据，参数如
```python3 -m pycluster2x.script.download_data --dst_path ./data_cache/ --data_host 10.12.76.155 --data_port 33508```

